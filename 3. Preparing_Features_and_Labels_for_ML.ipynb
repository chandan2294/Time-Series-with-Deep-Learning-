{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preparing Features and Labels for ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNP7vP83n4iaYm8XLsWaIiK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandan2294/Time-Series-with-Deep-Learning-/blob/master/Preparing_Features_and_Labels_for_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUXQAA4_l7fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww9cFNzqousU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aac4f557-9d01-4d9b-b5bc-af80800c2045"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLAxvLBSpFYv",
        "colab_type": "text"
      },
      "source": [
        "Create a simple dataset containing few instances (range from 0 to 20)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6yseQ6so3fh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "4bc8863c-b21a-42a4-ba16-3f8554d90545"
      },
      "source": [
        "dataset = tf.data.Dataset.range(20)\n",
        "for val in dataset:\n",
        "  print(val.numpy())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfBWxfJ_pewA",
        "colab_type": "text"
      },
      "source": [
        "Now, we'll window the data into chucks of five items shifting by one each time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVsNlRm6poDA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "77f0bf6e-a193-45b2-b21a-0d4d5eb6211e"
      },
      "source": [
        "dataset = tf.data.Dataset.range(20)\n",
        "dataset = dataset.window(5, shift = 1) #Window the data into 5 chucks and shift by 1\n",
        "for window_dataset in dataset:\n",
        "  for val in window_dataset:\n",
        "    print(val.numpy(), end = \" \")\n",
        "  print()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1 2 3 4 \n",
            "1 2 3 4 5 \n",
            "2 3 4 5 6 \n",
            "3 4 5 6 7 \n",
            "4 5 6 7 8 \n",
            "5 6 7 8 9 \n",
            "6 7 8 9 10 \n",
            "7 8 9 10 11 \n",
            "8 9 10 11 12 \n",
            "9 10 11 12 13 \n",
            "10 11 12 13 14 \n",
            "11 12 13 14 15 \n",
            "12 13 14 15 16 \n",
            "13 14 15 16 17 \n",
            "14 15 16 17 18 \n",
            "15 16 17 18 19 \n",
            "16 17 18 19 \n",
            "17 18 19 \n",
            "18 19 \n",
            "19 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aasMdTbmqceu",
        "colab_type": "text"
      },
      "source": [
        "We see that this gives us the output of first five items, and then second five items, and then the third and so on. At the end of the dataset, when there isn't enough data to give us five items, you'll see shorter lines.\n",
        "\n",
        "To just get chunks of five records, we'll set *drop_reminder = True*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJQQWodbq_M3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "1bd43a2a-6f43-4958-b47e-cf87863c7195"
      },
      "source": [
        "dataset = tf.data.Dataset.range(20)\n",
        "dataset = dataset.window(5, shift = 1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window:window.batch(5))\n",
        "for window in dataset:\n",
        "  print(window.numpy())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4]\n",
            "[1 2 3 4 5]\n",
            "[2 3 4 5 6]\n",
            "[3 4 5 6 7]\n",
            "[4 5 6 7 8]\n",
            "[5 6 7 8 9]\n",
            "[ 6  7  8  9 10]\n",
            "[ 7  8  9 10 11]\n",
            "[ 8  9 10 11 12]\n",
            "[ 9 10 11 12 13]\n",
            "[10 11 12 13 14]\n",
            "[11 12 13 14 15]\n",
            "[12 13 14 15 16]\n",
            "[13 14 15 16 17]\n",
            "[14 15 16 17 18]\n",
            "[15 16 17 18 19]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnrmy34urbCs",
        "colab_type": "text"
      },
      "source": [
        "Now we split it into x's and y's or features and labels. We'll take the last coulmn as the label, and we'll split using a lambda. We'll split the data into column - 1, which is all the coulmns except the last one, and minus one which is the last column only. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9UjOWBir3BB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "79b7c0a1-539f-435b-9bf8-72d7c68c6cc9"
      },
      "source": [
        "dataset = tf.data.Dataset.range(20)\n",
        "dataset = dataset.window(5, shift = 1, drop_remainder = True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
        "for x, y in dataset:\n",
        "  print(x.numpy(), y.numpy())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3] [4]\n",
            "[1 2 3 4] [5]\n",
            "[2 3 4 5] [6]\n",
            "[3 4 5 6] [7]\n",
            "[4 5 6 7] [8]\n",
            "[5 6 7 8] [9]\n",
            "[6 7 8 9] [10]\n",
            "[ 7  8  9 10] [11]\n",
            "[ 8  9 10 11] [12]\n",
            "[ 9 10 11 12] [13]\n",
            "[10 11 12 13] [14]\n",
            "[11 12 13 14] [15]\n",
            "[12 13 14 15] [16]\n",
            "[13 14 15 16] [17]\n",
            "[14 15 16 17] [18]\n",
            "[15 16 17 18] [19]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTniyhFGsgYr",
        "colab_type": "text"
      },
      "source": [
        "Next is to shuffle the data. This is acheived with the shuffle method. This helps us rearrange the data such that it doesn't accidentally introduce a sequence bias. \n",
        "\n",
        "Sequence Bias: Sequence bias is when the order of things can impact the selection of things. For example, if I were to ask you your favorite TV show, and listed \"Game of Thrones\", \"Killing Eve\", \"Travellers\" and \"Doctor Who\" in that order, you're probably more likely to select 'Game of Thrones' as you are familiar with it, and it's the first thing you see. Even if it is equal to the other TV shows. So, when training data in a dataset, we don't want the sequence to impact the training in a similar way, so it's good to shuffle them up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SHfADoes9Bj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "20767efa-86c7-439d-82ef-b1d70d8b1baa"
      },
      "source": [
        "dataset = tf.data.Dataset.range(20)\n",
        "dataset = dataset.window(5, shift = 1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
        "dataset = dataset.shuffle(buffer_size=20)\n",
        "for x, y in dataset:\n",
        "  print(x.numpy(), y.numpy())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 7  8  9 10] [11]\n",
            "[13 14 15 16] [17]\n",
            "[0 1 2 3] [4]\n",
            "[12 13 14 15] [16]\n",
            "[ 8  9 10 11] [12]\n",
            "[15 16 17 18] [19]\n",
            "[2 3 4 5] [6]\n",
            "[4 5 6 7] [8]\n",
            "[11 12 13 14] [15]\n",
            "[3 4 5 6] [7]\n",
            "[6 7 8 9] [10]\n",
            "[14 15 16 17] [18]\n",
            "[10 11 12 13] [14]\n",
            "[ 9 10 11 12] [13]\n",
            "[1 2 3 4] [5]\n",
            "[5 6 7 8] [9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO_6eVuJtld_",
        "colab_type": "text"
      },
      "source": [
        "Finally comes batching. By setting a batch size of three, our data gets batched into 3 x's and 3 y's at a time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l-eKRA1tx8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "fe30d00e-4f46-4698-e50d-9b575f006bf8"
      },
      "source": [
        "dataset = tf.data.Dataset.range(20)\n",
        "dataset = dataset.window(5, shift = 1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
        "dataset = dataset.shuffle(buffer_size=20)\n",
        "dataset = dataset.batch(3).prefetch(1)\n",
        "for x, y in dataset:\n",
        "  print(\"X = \", x.numpy())\n",
        "  print('y = ', y.numpy())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X =  [[ 2  3  4  5]\n",
            " [ 0  1  2  3]\n",
            " [14 15 16 17]]\n",
            "y =  [[ 6]\n",
            " [ 4]\n",
            " [18]]\n",
            "X =  [[6 7 8 9]\n",
            " [1 2 3 4]\n",
            " [3 4 5 6]]\n",
            "y =  [[10]\n",
            " [ 5]\n",
            " [ 7]]\n",
            "X =  [[ 5  6  7  8]\n",
            " [13 14 15 16]\n",
            " [ 9 10 11 12]]\n",
            "y =  [[ 9]\n",
            " [17]\n",
            " [13]]\n",
            "X =  [[12 13 14 15]\n",
            " [ 7  8  9 10]\n",
            " [ 4  5  6  7]]\n",
            "y =  [[16]\n",
            " [11]\n",
            " [ 8]]\n",
            "X =  [[15 16 17 18]\n",
            " [ 8  9 10 11]\n",
            " [10 11 12 13]]\n",
            "y =  [[19]\n",
            " [12]\n",
            " [14]]\n",
            "X =  [[11 12 13 14]]\n",
            "y =  [[15]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
